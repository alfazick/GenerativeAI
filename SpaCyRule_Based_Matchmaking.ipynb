{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRZAZrQwU12EoK5aPJroU8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfazick/GenerativeAI/blob/main/SpaCyRule_Based_Matchmaking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FllIwRd1AO5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9dxrPbyy2-b",
        "outputId": "845bcc18-8c04-4088-d482-70cdd6d7b27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m587.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!python -m spacy download en_core_web_lg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly extract information from text by matching patterns and phrases\n",
        "# use morphological features, POS tags, regex\n",
        "# to form pattern objects to feed to the Matcher objects"
      ],
      "metadata": {
        "id": "kRqpNZiM1Ieb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token-based matching\n",
        "# PhraseMatcher\n",
        "# EntityRuler\n",
        "# Combining spaCy modesl and matchers\n"
      ],
      "metadata": {
        "id": "zQfLd67H1lt-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Token Based Matching\n",
        "# Matching rules can refer to the token or it's linguistic attributes\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "A0-Wxy7s2FJQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Good MORnIng, I want to reserve a ticket.\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LOWER\":\"good\"},{\"LOWER\":\"morning\"},{\"IS_PUNCT\":True}]\n",
        "matcher.add(\"morningGreeting\",[pattern])\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    m_span = doc[start:end]\n",
        "    print(start,end, m_span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elgPadjN293b",
        "outputId": "1d6f4fc6-736b-4a67-f152-63d7aaf69fab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3 Good MORnIng,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "def address_extractor(text,address_pattern,nlp_model):\n",
        "    matcher = Matcher(nlp_model.vocab)\n",
        "    # Add the address pattern to the matcher\n",
        "    matcher.add(\"ADDRESS\", [address_pattern])\n",
        "    doc = nlp_model(text)\n",
        "    matches = matcher(doc)\n",
        "    # Return both the matches and the doc to extract text outside\n",
        "    return matches, doc\n",
        "\n",
        "\n",
        "# Define a pattern for a basic address: arbitrary digit number, street name, street type, optional zip code\n",
        "address_pattern = [\n",
        "    {\"SHAPE\": \"d+\"},  # Street number: one or more digits\n",
        "    {\"IS_ALPHA\": True, \"LENGTH\": {\">=\": 2}},  # Street name: two or more alphabetical characters\n",
        "    {\"LOWER\": {\"IN\": [\"st\", \"street\", \"ave\", \"avenue\", \"blvd\", \"boulevard\", \"road\", \"rd\"]}},  # Street type\n",
        "    {\"OP\": \"?\"},  # Make the previous token optional\n",
        "    {\"SHAPE\": \"dddd\", \"OP\": \"?\"},  # Optional zip code: 5 digits\n",
        "    {\"TEXT\": \"-\", \"OP\": \"?\"},  # Optional hyphen for extended zip code format\n",
        "    {\"SHAPE\": \"dddd\", \"OP\": \"?\"}  # Optional extension of the zip code\n",
        "]\n",
        "\n",
        "address_pattern = [\n",
        "    {\"SHAPE\": \"d+\"},  # Street number: one or more digits\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"*\", \"LENGTH\": {\">=\": 1}},  # Optional street name: one or more alphabetical characters\n",
        "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # Optional punctuation\n",
        "    {\"LOWER\": {\"IN\": [\"st\", \"street\", \"ave\", \"avenue\", \"blvd\", \"boulevard\", \"road\", \"rd\", \"ln\", \"lane\", \"dr\", \"drive\"]}, \"OP\": \"?\"},  # Optional street type\n",
        "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # Optional punctuation\n",
        "    {\"SHAPE\": {\"REGEX\": \"^(\\\\d{5}(-\\\\d{4})?|[A-Z]{1,2}\\\\d[A-Z\\\\d]? \\\\d[A-Z]{2})$\"}, \"OP\": \"?\"}  # Optional zip code or postcode, supporting US and UK formats\n",
        "]\n",
        "address_pattern = [\n",
        "        {\"SHAPE\": \"d+\"},  # Street number\n",
        "        {\"IS_ALPHA\": True, \"OP\": \"?\"},  # Optional street direction (N, S, E, W)\n",
        "        {\"IS_ALPHA\": True},  # Street name\n",
        "        {\"LOWER\": {\"IN\": [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"drive\", \"dr\"]}},  # Street type\n",
        "    ]\n",
        "\n",
        "pseudo_addresses = [\n",
        "    \"123 Main St, Springfield, IL 62704\",\n",
        "    \"456 Elm Street, Apt 101, New York, NY 10025\",\n",
        "    \"789 Pine Avenue, Los Angeles, CA 90015\",\n",
        "    \"Unit 5, 250 Cherry Blvd, Seattle, WA 98104\",\n",
        "    \"12B High Tower, Gotham City, 99999\",\n",
        "    \"42 Douglas Adams Road, Sector ZZ9 Plural Z Alpha, 4242\",\n",
        "    \"88 Rising Sun Lane, Kyoto, 600-8216\",\n",
        "    \"1600 Pennsylvania Ave NW, Washington, DC 20500\",\n",
        "    \"221B Baker Street, London, NW1 6XE\",\n",
        "    \"Flat 4, 28 Marina Bay, Singapore, 018981\",\n",
        "    \"Let's meet at 123 Main St. and then go to 456 Elm Avenue for lunch.\"\n",
        "]\n",
        "\n",
        "texts = pseudo_addresses[:]\n",
        "\n",
        "# Testing\n",
        "for text in texts:\n",
        "    print(f\"Original Text: {text}\")\n",
        "    matches, doc = address_extractor(text, address_pattern, nlp)  # Adjusted to receive both matches and doc\n",
        "    for match_id, start, end in matches:\n",
        "        match_span = doc[start:end]  # Extracting match text here\n",
        "        print(f\"Match found: {match_span.text} (Start: {start}, End: {end})\")\n",
        "    if not matches:\n",
        "        print(\"No matches found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txJAF71w3u-n",
        "outputId": "4dce9365-9a11-4555-b2df-8fc5099152f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: 123 Main St, Springfield, IL 62704\n",
            "No matches found.\n",
            "Original Text: 456 Elm Street, Apt 101, New York, NY 10025\n",
            "No matches found.\n",
            "Original Text: 789 Pine Avenue, Los Angeles, CA 90015\n",
            "No matches found.\n",
            "Original Text: Unit 5, 250 Cherry Blvd, Seattle, WA 98104\n",
            "No matches found.\n",
            "Original Text: 12B High Tower, Gotham City, 99999\n",
            "No matches found.\n",
            "Original Text: 42 Douglas Adams Road, Sector ZZ9 Plural Z Alpha, 4242\n",
            "No matches found.\n",
            "Original Text: 88 Rising Sun Lane, Kyoto, 600-8216\n",
            "No matches found.\n",
            "Original Text: 1600 Pennsylvania Ave NW, Washington, DC 20500\n",
            "No matches found.\n",
            "Original Text: 221B Baker Street, London, NW1 6XE\n",
            "No matches found.\n",
            "Original Text: Flat 4, 28 Marina Bay, Singapore, 018981\n",
            "No matches found.\n",
            "Original Text: Let's meet at 123 Main St. and then go to 456 Elm Avenue for lunch.\n",
            "No matches found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define pattern for US-style addresses\n",
        "address_pattern = [\n",
        "    {\"SHAPE\": \"d+\"},  # Street number: one or more digits\n",
        "    {\"IS_ALPHA\": True, \"LENGTH\": {\">=\": 2}},  # Street name: two or more alphabetical characters\n",
        "    {\"LOWER\": {\"IN\": [\"st\", \"street\", \"ave\", \"avenue\", \"blvd\", \"boulevard\", \"road\", \"rd\"]}},  # Street type\n",
        "    {\"OP\": \"?\"},  # Make the previous token optional\n",
        "    {\"SHAPE\": \"dddd\", \"OP\": \"?\"},  # Optional zip code: 5 digits\n",
        "    {\"TEXT\": \"-\", \"OP\": \"?\"},  # Optional hyphen for extended zip code format\n",
        "    {\"SHAPE\": \"dddd\", \"OP\": \"?\"}  # Optional extension of the zip code\n",
        "]\n",
        "\n",
        "matcher.add(\"US_ADDRESS\", [address_pattern])\n",
        "\n",
        "text = \"Let's meet at 123 Main St. and then go to 456 Elm Avenue for lunch.\"\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "\n",
        "addresses = []\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]  # The matched span\n",
        "    addresses.append(span.text)\n",
        "print(addresses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPJtXbC97Qcd",
        "outputId": "54e37676-aef8-46bb-f7af-ce25d7b97e49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Using a small model for simplicity\n",
        "\n",
        "# Initialize the Matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define the pattern for street types\n",
        "street_type_pattern = [\n",
        "    {\"LOWER\": {\"IN\": [\"st\", \"street\", \"str\", \"ave\", \"avenue\", \"rd\", \"road\", \"blvd\", \"boulevard\", \"lane\", \"ln\", \"dr\", \"drive\"]}}\n",
        "]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"STREET_TYPE\", [street_type_pattern])\n",
        "\n",
        "def find_street_types(text):\n",
        "    # Process the text\n",
        "    doc = nlp(text)\n",
        "    # Find matches in the text\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    # Extract and return the matched street types\n",
        "    return [doc[start:end].text for match_id, start, end in matches]\n",
        "\n",
        "# Example text\n",
        "text = \"I've lived on Elm Street, Oak Rd, and Pine Avenue.\"\n",
        "\n",
        "# Find and print street types\n",
        "street_types = find_street_types(text)\n",
        "print(street_types)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPVlYaHO-XGX",
        "outputId": "8b2b12ee-6f27-4959-a03c-a8bebee16b92"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Street', 'Rd', 'Avenue']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Using a small model for simplicity\n",
        "\n",
        "# Initialize the Matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define the pattern to include the preceding word (street name) and the street type\n",
        "street_type_pattern = [\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"?\"},  # Optionally match an adjective (e.g., \"Old\" in \"Old Main Street\")\n",
        "    {\"IS_ALPHA\": True},  # The word immediately preceding the street type (street name)\n",
        "    {\"LOWER\": {\"IN\": [\"st.\",\"st\", \"street\", \"str\", \"ave\", \"avenue\", \"rd\", \"road\", \"blvd\", \"boulevard\", \"lane\", \"ln\", \"dr\", \"drive\"]}}  # Street type\n",
        "]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"STREET_NAME_AND_TYPE\", [street_type_pattern])\n",
        "\n",
        "def find_street_names_and_types(text):\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "    # Find matches in the text\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    # Extract and return the matched spans (street names and types)\n",
        "    return [doc[start:end].text for match_id, start, end in matches]\n",
        "\n",
        "pseudo_addresses = [\n",
        "    \"123 Main St, Springfield, IL 62704\",\n",
        "    \"456 Elm Street, Apt 101, New York, NY 10025\",\n",
        "    \"789 Pine Avenue, Los Angeles, CA 90015\",\n",
        "    \"Unit 5, 250 Cherry Blvd, Seattle, WA 98104\",\n",
        "    \"12B High Tower, Gotham City, 99999\",\n",
        "    \"42 Douglas Adams Road, Sector ZZ9 Plural Z Alpha, 4242\",\n",
        "    \"88 Rising Sun Lane, Kyoto, 600-8216\",\n",
        "    \"1600 Pennsylvania Ave NW, Washington, DC 20500\",\n",
        "    \"221B Baker Street, London, NW1 6XE\",\n",
        "    \"Flat 4, 28 Marina Bay, Singapore, 018981\",\n",
        "    \"Let's meet at 123 Main St. and then go to 456 Elm Avenue for lunch.\"\n",
        "]\n",
        "\n",
        "texts = pseudo_addresses[:]\n",
        "for text in texts:\n",
        "\n",
        "    # Find and print street names along with their types\n",
        "    street_names_and_types = find_street_names_and_types(text)\n",
        "    print(street_names_and_types)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guXdyV6z_uJW",
        "outputId": "98fc990e-423b-48a6-9518-ad6e847caf41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Main St']\n",
            "['Elm Street']\n",
            "['Pine Avenue']\n",
            "['Cherry Blvd']\n",
            "[]\n",
            "['Douglas Adams Road', 'Adams Road']\n",
            "['Rising Sun Lane', 'Sun Lane']\n",
            "['Pennsylvania Ave']\n",
            "['Baker Street']\n",
            "[]\n",
            "['Main St.', 'Elm Avenue']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding two patterns\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "doc = nlp(\"Good morning, I want to reserve a ticket. I will then say good evening!\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}, {\"IS_PUNCT\": True}]\n",
        "matcher.add(\"morningGreeting\", [pattern])\n",
        "\n",
        "pattern2 = [{\"LOWER\": \"good\"}, {\"LOWER\": \"evening\"}, {\"IS_PUNCT\": True}]\n",
        "matcher.add(\"eveningGreeting\", [pattern2])\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    pattern_name = nlp.vocab.strings[match_id]\n",
        "    m_span = doc[start:end]\n",
        "    print(start, end, m_span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEpygwH5AA6i",
        "outputId": "ac84497e-747e-4c62-ca65-fc9742632695"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3 Good morning,\n",
            "14 17 good evening!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "doc = nlp(\"123 Main St, Springfield, IL 62704\",)\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LENGTH\": 2}]\n",
        "matcher.add(\"onlyShort\", [pattern])\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    m_span = doc[start:end]\n",
        "    print(start, end, m_span.text)\n",
        "\n",
        "# Extract states?\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v3Mvou7CqdY",
        "outputId": "75910c5c-5b71-412a-fd30-f0e293f5690e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 3 St\n",
            "6 7 IL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the Matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define the pattern to include the preceding word (street name) and the street type\n",
        "street_type_pattern = [\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"?\"},  # Optionally match an adjective (e.g., \"Old\" in \"Old Main Street\")\n",
        "    {\"IS_ALPHA\": True},  # The word immediately preceding the street type (street name)\n",
        "    {\"LOWER\": {\"IN\": [\"st.\", \"st\", \"street\", \"str\", \"ave\", \"avenue\", \"rd\", \"road\", \"blvd\", \"boulevard\", \"lane\", \"ln\", \"dr\", \"drive\"]}},  # Street type\n",
        "]\n",
        "\n",
        "# Pattern for matching U.S. state abbreviations\n",
        "state_abbr_pattern = [\n",
        "    {\"LENGTH\": 2, \"IS_UPPER\": True}\n",
        "]\n",
        "\n",
        "# Add the patterns to the matcher\n",
        "matcher.add(\"STREET_NAME_AND_TYPE\", [street_type_pattern])\n",
        "matcher.add(\"STATE_ABBR\", [state_abbr_pattern])\n",
        "\n",
        "def find_street_names_types_states(text):\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "    # Find matches in the text\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    streets = []\n",
        "    states = []\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]  # The matched span\n",
        "        rule_id = nlp.vocab.strings[match_id]  # Get the pattern name\n",
        "        if rule_id == \"STREET_NAME_AND_TYPE\":\n",
        "            streets.append(span.text)\n",
        "        elif rule_id == \"STATE_ABBR\":\n",
        "            states.append(span.text)\n",
        "\n",
        "    return streets, states\n",
        "\n",
        "pseudo_addresses = [\n",
        "    \"123 Main St, Springfield, IL 62704\",\n",
        "    \"456 Elm Street, Apt 101, New York, NY 10025\",\n",
        "    \"789 Pine Avenue, Los Angeles, CA 90015\",\n",
        "    \"Unit 5, 250 Cherry Blvd, Seattle, WA 98104\",\n",
        "    \"12B High Tower, Gotham City, 99999\",\n",
        "    \"42 Douglas Adams Road, Sector ZZ9 Plural Z Alpha, 4242\",\n",
        "    \"88 Rising Sun Lane, Kyoto, 600-8216\",\n",
        "    \"1600 Pennsylvania Ave NW, Washington, DC 20500\",\n",
        "    \"221B Baker Street, London, NW1 6XE\",\n",
        "    \"Flat 4, 28 Marina Bay, Singapore, 018981\",\n",
        "    \"Let's meet at 123 Main St. and then go to 456 Elm Avenue for lunch.\"\n",
        "]\n",
        "\n",
        "for text in pseudo_addresses:\n",
        "    street_names_and_types, state_abbrs = find_street_names_types_states(text)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Street Names and Types: {street_names_and_types}\")\n",
        "    print(f\"State Abbreviations: {state_abbrs}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST5e9UCDC_01",
        "outputId": "82263797-094f-4268-8f70-6c2b22065335"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 123 Main St, Springfield, IL 62704\n",
            "Street Names and Types: ['Main St']\n",
            "State Abbreviations: ['IL']\n",
            "---\n",
            "Text: 456 Elm Street, Apt 101, New York, NY 10025\n",
            "Street Names and Types: ['Elm Street']\n",
            "State Abbreviations: ['NY']\n",
            "---\n",
            "Text: 789 Pine Avenue, Los Angeles, CA 90015\n",
            "Street Names and Types: ['Pine Avenue']\n",
            "State Abbreviations: ['CA']\n",
            "---\n",
            "Text: Unit 5, 250 Cherry Blvd, Seattle, WA 98104\n",
            "Street Names and Types: ['Cherry Blvd']\n",
            "State Abbreviations: ['WA']\n",
            "---\n",
            "Text: 12B High Tower, Gotham City, 99999\n",
            "Street Names and Types: []\n",
            "State Abbreviations: []\n",
            "---\n",
            "Text: 42 Douglas Adams Road, Sector ZZ9 Plural Z Alpha, 4242\n",
            "Street Names and Types: ['Douglas Adams Road', 'Adams Road']\n",
            "State Abbreviations: []\n",
            "---\n",
            "Text: 88 Rising Sun Lane, Kyoto, 600-8216\n",
            "Street Names and Types: ['Rising Sun Lane', 'Sun Lane']\n",
            "State Abbreviations: []\n",
            "---\n",
            "Text: 1600 Pennsylvania Ave NW, Washington, DC 20500\n",
            "Street Names and Types: ['Pennsylvania Ave']\n",
            "State Abbreviations: ['NW', 'DC']\n",
            "---\n",
            "Text: 221B Baker Street, London, NW1 6XE\n",
            "Street Names and Types: ['Baker Street']\n",
            "State Abbreviations: []\n",
            "---\n",
            "Text: Flat 4, 28 Marina Bay, Singapore, 018981\n",
            "Street Names and Types: []\n",
            "State Abbreviations: []\n",
            "---\n",
            "Text: Let's meet at 123 Main St. and then go to 456 Elm Avenue for lunch.\n",
            "Street Names and Types: ['Main St.', 'Elm Avenue']\n",
            "State Abbreviations: []\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation: Funneling Approach:To consider\n",
        "# 1) Step extract states possibly?\n",
        "# 2) Work with text that possibly contain address and extract them\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.util import filter_spans  # Utility to handle overlapping spans\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define the pattern to include the preceding word (street name) and the street type\n",
        "street_type_pattern = [\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"?\"},  # Optionally match an adjective (e.g., \"Old\" in \"Old Main Street\")\n",
        "    {\"IS_ALPHA\": True},  # The word immediately preceding the street type (street name)\n",
        "    {\"LOWER\": {\"IN\": [\"st.\", \"st\", \"street\", \"str\", \"ave\", \"avenue\", \"rd\", \"road\", \"blvd\", \"boulevard\", \"lane\", \"ln\", \"dr\", \"drive\"]}},  # Street type\n",
        "]\n",
        "\n",
        "# Pattern for matching U.S. state abbreviations\n",
        "state_abbr_pattern = [\n",
        "    {\"LENGTH\": 2, \"IS_UPPER\": True, \"TEXT\": {\"REGEX\": \"^(AL|AK|AZ|AR|CA|CO|CT|DE|FL|GA|HI|ID|IL|IN|IA|KS|KY|LA|ME|MD|MA|MI|MN|MS|MO|MT|NE|NV|NH|NJ|NM|NY|NC|ND|OH|OK|OR|PA|RI|SC|SD|TN|TX|UT|VT|VA|WA|WV|WI|WY)$\"}}\n",
        "]\n",
        "\n",
        "# Add the patterns to the matcher\n",
        "matcher.add(\"STREET_NAME_AND_TYPE\", [street_type_pattern])\n",
        "matcher.add(\"STATE_ABBR\", [state_abbr_pattern])\n",
        "\n",
        "def extract_relevant_sentences(text):\n",
        "    doc = nlp(text)\n",
        "    relevant_sentences = set()\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        if any(matcher(nlp(sent.text))):\n",
        "            relevant_sentences.add(sent.text)\n",
        "\n",
        "    return list(relevant_sentences)\n",
        "\n",
        "def extract_addresses_from_sentences(sentences):\n",
        "    extracted_addresses = []\n",
        "    for sentence in sentences:\n",
        "        doc = nlp(sentence)\n",
        "        matches = matcher(doc)\n",
        "        addresses = [doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == \"STREET_NAME_AND_TYPE\"]\n",
        "        extracted_addresses.extend(addresses)\n",
        "    return extracted_addresses\n",
        "\n",
        "# Example long text\n",
        "long_text = \"\"\"\n",
        "This weekend promises to be an adventure. We're kicking things off with a morning hike in the local park,\n",
        "where the trails wind through ancient forests and open up to breathtaking views of the valley.\n",
        "Afterward, a quick visit to the farmer's market downtown is a must, where the freshest produce and homemade goodies await.\n",
        "\n",
        "Lunch is planned at a small, hidden gem of a cafe known for its farm-to-table approach and quirky decor.\n",
        "It's located right off the main plaza, but without a sign, it's a place you'd only know if you were a local.\n",
        "The afternoon will be spent at the museum on 5th, showcasing a new exhibit on the golden age of science fiction.\n",
        "\n",
        "Dinner reservations are at 7 PM at 'The Orchard', a cozy restaurant nestled within the city's\n",
        "historical district at 456 Elm Street, Apt 101, New York, NY.\n",
        "Known for its innovative cuisine and award-winning chef, it's the perfect spot to celebrate our journey's beginning.\n",
        "\n",
        "The night doesn't end there. We've tickets to a late show at the Grand Theater,\n",
        "renowned for its opulent design and acoustics that make every performance unforgettable.\n",
        "As the curtain falls, our thoughts will already be on tomorrow's plans, which include a visit\n",
        "to the famous 789 Pine Avenue, Los Angeles, CA, for a guided tour of historic homes and gardens.\n",
        "\n",
        "Sunday is left deliberately open, a canvas for spontaneity. Perhaps a day at the beach,\n",
        "or exploring the city's array of boutique shops and art galleries.\n",
        "As the sun sets on our weekend adventure, we'll gather for drinks at a rooftop\n",
        "bar overlooking the skyline, reflecting on the memories made and the tales to tell.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Step 1: Filter sentences that potentially contain U.S. states\n",
        "relevant_sentences = extract_relevant_sentences(long_text)\n",
        "\n",
        "# Step 2: Extract addresses from those sentences\n",
        "extracted_addresses = extract_addresses_from_sentences(relevant_sentences)\n",
        "\n",
        "print(\"Relevant Sentences:\", relevant_sentences)\n",
        "print(\"Extracted Addresses:\", extracted_addresses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2oAxJLQD2Fk",
        "outputId": "857ecde6-92e9-4e44-909f-4510a162966e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant Sentences: [\"Dinner reservations are at 7 PM at 'The Orchard', a cozy restaurant nestled within the city's \\nhistorical district at 456 Elm Street, Apt 101, New York, NY. \\n\", \"As the curtain falls, our thoughts will already be on tomorrow's plans, which include a visit \\nto the famous 789 Pine Avenue, Los Angeles, CA, for a guided tour of historic homes and gardens.\\n\\n\"]\n",
            "Extracted Addresses: ['Elm Street', 'Pine Avenue']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# looking for specific tag can be interesting approach\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "doc = nlp(\"Will you go there?\")\n",
        "pattern = [{\"IS_SENT_START\": True, \"TAG\": \"MD\"}]\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add(\"AUX_PATTERN\" ,[pattern])\n",
        "matches = matcher(doc)\n",
        "print(len(matches))\n",
        "mid, start, end = matches[0]\n",
        "print(start, end, doc[start:end])\n",
        "doc2 = nlp(\"I might go there.\")\n",
        "print(matcher(doc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsn1gWe_E0rt",
        "outputId": "0be641b6-80ee-45cb-d118-fefba1949558"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0 1 Will\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern to match tokens that spaCy recognizes as numerical\n",
        "pattern = [{\"LIKE_NUM\": True}]\n",
        "matcher.add(\"NUM_PATTERN\", [pattern])\n",
        "\n",
        "# Example text with mixed numerical representations\n",
        "text = \"There are three apples for two dollars each. In total, that's six dollars.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Find matches in the document\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    print(start, end, doc[start:end])\n",
        "\n",
        "# Testing on a more complex text\n",
        "complex_text = \"The distance between the cities is one hundred kilometers, roughly 62 miles.\"\n",
        "doc2 = nlp(complex_text)\n",
        "print(matcher(doc2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWLM7OpVGrEz",
        "outputId": "16179825-1a32-41b5-cfc3-2ef7d9637fc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 3 three\n",
            "5 6 two\n",
            "14 15 six\n",
            "[(8020647245559105862, 6, 7), (8020647245559105862, 7, 8), (8020647245559105862, 11, 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")  # Load a spaCy medium model\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern that looks for an address starting with a number in word form\n",
        "address_pattern = [\n",
        "    {\"LIKE_NUM\": True},  # Number in word form\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # One or more alphabetical tokens for the street name\n",
        "    {\"LOWER\": {\"IN\": [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"lane\", \"ln\", \"drive\", \"dr\"]}},  # Street type\n",
        "]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"ADDRESS_IN_WORDS\", [address_pattern])\n",
        "\n",
        "# Example text\n",
        "text = \"Let's meet at one eighty-two Pine Street next Saturday.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Find matches in the text\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Extract and print the matched spans\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]  # The matched span\n",
        "    print(f\"Matched address: {span.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4QJ-fWJIdL",
        "outputId": "9ba8cecc-bcb8-4691-ee7e-a1767e22c3d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched address: two Pine Street\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Syntax Support and Regex\n",
        "\n",
        "# in operator\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "doc = nlp(\"Good morning, I'm here. I'll say good evening!!\")\n",
        "pattern = [{\"LOWER\": \"good\"},\n",
        "{\"LOWER\": {\"IN\": [\"morning\", \"evening\"]}},{\"IS_PUNCT\": True}]\n",
        "matcher.add(\"greetings\",  [pattern])\n",
        "matches = matcher(doc)\n",
        "for mid, start, end in matches:\n",
        "  print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88dKnwv8MGnN",
        "outputId": "878e8060-e9e1-4100-b7a5-ac0005c4c72d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3 Good morning,\n",
            "10 13 good evening!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# length attribute\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "doc = nlp(\"I suffered from Trichotillomania when I was in college. The doctor prescribed me Psychosomatic medicine.\")\n",
        "pattern = [{\"LENGTH\": {\">=\" : 10}}]\n",
        "matcher.add(\"longWords\",  [pattern])\n",
        "matches = matcher(doc)\n",
        "for mid, start, end in matches:\n",
        "  print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqqvpNMxRjMo",
        "outputId": "e188546e-f379-4794-9198-4007edf8ae91"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 4 Trichotillomania\n",
            "12 13 prescribed\n",
            "14 15 Psychosomatic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")  # Load a spaCy medium model\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern that uses POS tags to improve address matching\n",
        "address_pattern = [\n",
        "    {\"LIKE_NUM\": True, \"POS\": \"NUM\"},  # Numeric word form, tagged as numeral\n",
        "    {\"POS\": \"PROPN\", \"OP\": \"+\"},  # One or more proper nouns for the street name\n",
        "    {\"POS\": \"NOUN\", \"LOWER\": {\"IN\": [\"street\", \"avenue\", \"road\", \"boulevard\", \"lane\", \"drive\"]}},  # Street type as a noun\n",
        "]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"ADDRESS_IN_WORDS_POS\", [address_pattern])\n",
        "\n",
        "# Example text\n",
        "text = \"We're heading to twenty two Baker Street for the event.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Find matches in the text\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Extract and print the matched spans\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]  # The matched span\n",
        "    print(f\"Matched address: {span.text}\")\n"
      ],
      "metadata": {
        "id": "aEfBICXIRpZ6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"My name is Alice and his name was Elliot.\")\n",
        "pattern = [{\"LOWER\": \"name\"},{\"LEMMA\": \"be\"},{}]\n",
        "matcher.add(\"pickName\", [pattern])\n",
        "for mid, start, end in matcher(doc):\n",
        "  print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiO5Wu29RxYY",
        "outputId": "7d39291b-a240-4421-a399-5e125c17d99f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 4 name is Alice\n",
            "6 9 name was Elliot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define the pattern to extract street addresses written with numbers in words\n",
        "address_pattern = [\n",
        "    {\"LIKE_NUM\": True},  # Street number in word form\n",
        "    {\"POS\": {\"IN\": [\"PROPN\", \"NOUN\"]}},  # Street name as a proper noun or noun\n",
        "    {\"LEMMA\": {\"IN\": [\"street\", \"avenue\", \"road\", \"boulevard\", \"lane\", \"drive\"]}, \"POS\": \"NOUN\"}  # Street type\n",
        "]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"STREET_ADDRESS_IN_WORDS\", [address_pattern])\n",
        "\n",
        "# Example text with addresses written in words\n",
        "text = \"They live on twenty two Baker Street. Another friend lives on thirty four Elm Avenue.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Apply the matcher to the processed document\n",
        "matches = matcher(doc)\n",
        "print(matches)\n",
        "# Print the matched spans\n",
        "for match_id, start, end in matches:\n",
        "    print(f\"Matched address: {doc[start:end]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC1Dz-p7SL1M",
        "outputId": "f7e850af-c868-4f90-e38b-727e28f80cdc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define patterns to capture numeric street numbers in word form, followed by a street name and type\n",
        "# This approach uses a combination of POS tagging and pattern flexibility to improve match accuracy\n",
        "address_pattern = [\n",
        "    {\"POS\": \"NUM\", \"OP\": \"+\"},  # One or more numeric tokens, allowing for multi-word numbers\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # One or more tokens for the street name, may include proper nouns and common nouns\n",
        "    {\"LEMMA\": {\"IN\": [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"lane\", \"ln\", \"drive\", \"dr\"]}, \"POS\": \"NOUN\"}  # Specific street types as nouns\n",
        "]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"STREET_ADDRESS\", [address_pattern])\n",
        "\n",
        "# Example text with addresses written in words\n",
        "text = \"Let's meet at twenty two Baker Street. Don't forget the party at one hundred First Avenue.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Apply the matcher to the processed document\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Print the matched spans\n",
        "for match_id, start, end in matches:\n",
        "    print(f\"Matched address: {doc[start:end]}\")\n"
      ],
      "metadata": {
        "id": "sGm_pAOvSebo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seems that funneling is better approach\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Adjusted pattern focusing on street types\n",
        "address_pattern = [\n",
        "    {\"POS\": \"PROPN\", \"OP\": \"*\"},  # Optional proper nouns for street names\n",
        "    {\"LEMMA\": {\"IN\": [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"lane\", \"ln\", \"drive\", \"dr\"]}, \"POS\": \"NOUN\"}  # Street type\n",
        "]\n",
        "\n",
        "matcher.add(\"STREET_ADDRESS\", [address_pattern])\n",
        "\n",
        "def extract_addresses(text):\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    addresses = []\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        # Extend the match backwards to include number words\n",
        "        num_start = start\n",
        "        while num_start > 0 and doc[num_start - 1].like_num:\n",
        "            num_start -= 1\n",
        "        addresses.append(doc[num_start:end].text)\n",
        "\n",
        "    return addresses\n",
        "\n",
        "# Example text\n",
        "text = \"They moved to one hundred twenty-two Elm Street after living on forty-two Maple Avenue for years.\"\n",
        "\n",
        "# Extract addresses\n",
        "addresses = extract_addresses(text)\n",
        "print(\"Extracted Addresses:\", addresses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFfySxOfSy_s",
        "outputId": "ecd59a97-03f8-4f0e-c5bb-071bdc6d4a04"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Addresses: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def extract_street_addresses(doc):\n",
        "    addresses = []\n",
        "    # Define street type keywords for pattern matching\n",
        "    street_types = [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"lane\", \"ln\", \"drive\", \"dr\"]\n",
        "    # Iterate through tokens to find potential addresses based on street type\n",
        "    for token in doc:\n",
        "        if token.lemma_ in street_types:\n",
        "            # Start from the token, move backwards to collect the street number and name\n",
        "            start = token.i\n",
        "            while start > 0 and (doc[start - 1].like_num or doc[start - 1].pos_ in [\"PROPN\", \"NOUN\"]):\n",
        "                start -= 1\n",
        "            # Create a span from the start to the current token's position + 1 (to include the street type token itself)\n",
        "            span = Span(doc, start, token.i + 1, label=\"ADDRESS\")\n",
        "            addresses.append(span.text)\n",
        "    return addresses\n",
        "\n",
        "# Example text\n",
        "text = \"They first lived at twenty two Baker Street before moving to one hundred twenty-three Elm Avenue. Another place was at fifty First Avenue.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract addresses\n",
        "addresses = extract_street_addresses(doc)\n",
        "print(\"Extracted Addresses:\", addresses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rinwiEBTF7z",
        "outputId": "7f3ab889-613e-4870-a976-ad016cb2cb91"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Addresses: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Span, Token\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Custom function to check if a token or span starts with a number (in words)\n",
        "def starts_with_number(text):\n",
        "    number_words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten',\n",
        "                    'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen',\n",
        "                    'eighteen', 'nineteen', 'twenty']\n",
        "    # Check if the first word of the text is in the number_words list\n",
        "    first_word = text.split()[0].lower()\n",
        "    return first_word in number_words\n",
        "\n",
        "# Function to extract addresses with numbers spelled out\n",
        "def extract_spelled_out_addresses(doc):\n",
        "    addresses = []\n",
        "    street_type_keywords = [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"lane\", \"ln\", \"drive\", \"dr\"]\n",
        "\n",
        "    for token in doc:\n",
        "        # Check if the token is a street type\n",
        "        if token.text.lower() in street_type_keywords:\n",
        "            # Create a span for the potential address\n",
        "            start = token.i - 2 if token.i >= 2 else 0\n",
        "            end = token.i + 1\n",
        "            address_span = doc[start:end]\n",
        "\n",
        "            # Check if the span starts with a number (in words)\n",
        "            if starts_with_number(address_span.text):\n",
        "                addresses.append(address_span.text)\n",
        "\n",
        "    return addresses\n",
        "\n",
        "# Example text\n",
        "text = \"They first lived at twenty two Baker Street before moving to one hundred twenty three Elm Avenue. Another place was at fifty First Avenue.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract addresses\n",
        "addresses = extract_spelled_out_addresses(doc)\n",
        "print(\"Extracted Addresses:\", addresses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_85dopMTauc",
        "outputId": "9806bb75-e9a0-4b8e-e876-1c4b50440e69"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Addresses: ['two Baker Street', 'three Elm Avenue']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Pattern to capture commonly mistyped numeric values in the context of an address\n",
        "# For simplicity, this example focuses on mistyped numbers 1-9, but you can expand this\n",
        "pattern = [\n",
        "    {\"TEXT\": {\"REGEX\": \"^(one|two|three|four|five|six|seven|eight|nine|1|2|3|4|5|6|7|8|9|onw|tow|thre|foru|fiv|sxi|sven|egiht|nien)$\"}},\n",
        "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # Street name\n",
        "    {\"LOWER\": {\"IN\": [\"street\", \"st\", \"avenue\", \"ave\", \"road\", \"rd\", \"boulevard\", \"blvd\", \"lane\", \"ln\", \"drive\", \"dr\"]}},  # Street type\n",
        "]\n",
        "\n",
        "matcher.add(\"MISTYPED_NUM_STREET\", [pattern])\n",
        "\n",
        "# Example text with a mistyped numeric value\n",
        "text = \"Let's meet at onw Main Street.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Apply the matcher to the processed document\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Print the matched spans\n",
        "for match_id, start, end in matches:\n",
        "    print(f\"Mistyped Address: {doc[start:end]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmAQDvZVTufO",
        "outputId": "e671112c-7849-46cb-b97c-349020d7fbd2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistyped Address: onw Main Street\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Example pattern to capture street types and possibly the street name\n",
        "# Note: Direct regex use is limited to the TEXT field; other attributes are used for structural matching\n",
        "patterns = [\n",
        "    {\"IS_DIGIT\": True, \"OP\": \"?\"},  # Optional digit (street number)\n",
        "    {\"POS\": \"PROPN\", \"OP\": \"+\"},  # One or more proper nouns (street name)\n",
        "    {\"TEXT\": {\"REGEX\": \"^(Street|St\\.|Avenue|Ave\\.|Road|Rd\\.|Boulevard|Blvd\\.)$\"}, \"OP\": \"?\"},  # Street type with regex\n",
        "]\n",
        "\n",
        "matcher.add(\"STREET_ADDRESS\", [patterns])\n",
        "\n",
        "# Example text\n",
        "text = \"They live at 123 Elm Street. Another place is on Pine Ave. Let's meet at the corner of 4th and Main.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    print(\"Matched address:\", span.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPc53Z16ULiJ",
        "outputId": "6c7b5206-7645-4cc6-c1a4-9575ddcff562"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched address: 123 Elm\n",
            "Matched address: 123 Elm Street\n",
            "Matched address: Elm\n",
            "Matched address: Elm Street\n",
            "Matched address: Street\n",
            "Matched address: Pine\n",
            "Matched address: Ave\n",
            "Matched address: Pine Ave\n",
            "Matched address: Main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 03 PhraseMatcher and Entity Ruler\n",
        "\n",
        "# matching long dictionaries\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "\n",
        "terms = [\"Angela Merkel\", \"Donald Trump\"]\n",
        "patterns = [nlp.make_doc(term) for term in terms]\n",
        "\n",
        "matcher.add(\"politiciansList\", None, *patterns)\n",
        "\n",
        "doc = nlp(\"3 EU leaders met in Berlin. German chancellor Angela Merkel first welcomed the US president Donald Trump. The following day Alexis Tsipras joined them in Brandenburg.\")\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "for mid, start, end in matches:\n",
        "    print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llT7KRuNVhat",
        "outputId": "95604d56-ab30-4e24-b77e-83554d787377"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 11 Angela Merkel\n",
            "16 18 Donald Trump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "\n",
        "# Common street types as terms\n",
        "street_types = [\"Street\", \"Avenue\", \"Road\", \"Boulevard\", \"Lane\", \"Drive\", \"Terrace\", \"Place\", \"Square\", \"Circle\"]\n",
        "# Create patterns from the street types\n",
        "patterns = [nlp.make_doc(street_type) for street_type in street_types]\n",
        "matcher.add(\"STREET_TYPES\", None, *patterns)\n",
        "\n",
        "# Example text with several street names and types\n",
        "text = \"I've lived on Elm Street and Pine Avenue. My friend moved to Birch Road. We plan to visit Maple Boulevard next week.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "for mid, start, end in matches:\n",
        "    # Extend the match to potentially include the street number or name\n",
        "    # This example simply prints the match, but you could expand this logic to include nearby tokens\n",
        "    print(\"Matched street type:\", doc[start:end])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iguf7YcckzY",
        "outputId": "ba4377c2-52cd-42b8-89c7-ae946384afe7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched street type: Street\n",
            "Matched street type: Avenue\n",
            "Matched street type: Road\n",
            "Matched street type: Boulevard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "terms = [\"Asset\", \"Investment\", \"Derivatives\", \"Demand\",  \"Market\"]\n",
        "patterns = [nlp.make_doc(term) for term in terms]\n",
        "matcher.add(\"financeTerms\", patterns)\n",
        "doc = nlp(\"During the last decade, derivatives market became an asset class of their own and influenced the financial landscape strongly.\")\n",
        "matches = matcher(doc)\n",
        "for mid, start, end in matches:\n",
        "  print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRQ9x_VTc6B8",
        "outputId": "37fb8507-5350-4313-e9f0-2fca89436ee2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 6 derivatives\n",
            "6 7 market\n",
            "9 10 asset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "\n",
        "# List of common street types\n",
        "street_types = [\"street\", \"ave\", \"road\", \"boulevard\", \"lane\", \"drive\", \"terrace\", \"place\", \"square\", \"circle\"]\n",
        "patterns = [nlp.make_doc(street_type) for street_type in street_types]\n",
        "matcher.add(\"STREET_TYPES\", patterns)\n",
        "\n",
        "text = \"I used to live on Maple Avenue but recently moved to Pine Road. Let's meet at the corner of 5th Avenue and 42nd Street.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "for mid, start, end in matches:\n",
        "    # Assuming the street name precedes the street type, look 1-3 tokens before the match\n",
        "    # Adjust the range as necessary based on your data\n",
        "    match_start = max(start - 3, 0) # magic number previous 3 words !!!\n",
        "    match_end = end  # The end of the match is the end of the street type\n",
        "    print(\"Potential address:\", doc[match_start:match_end])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFv3DYR9dAOx",
        "outputId": "3dab466b-d6a6-470b-9579-edbe7fc08ea7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Potential address: moved to Pine Road\n",
            "Potential address: Avenue and 42nd Street\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
        "ip_nums = [\"127.0.0.0\", \"127.256.0.0\"]\n",
        "patterns = [nlp.make_doc(ip) for ip in ip_nums]\n",
        "matcher.add(\"IPNums\", patterns)\n",
        "doc = nlp(\"This log contains the following IP addresses: 192.1.1.1 and 192.12.1.1 and 192.160.1.1 .\")\n",
        "for mid, start, end in matcher(doc):\n",
        "  print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DKxKxBUdffw",
        "outputId": "ab30551c-c829-4574-bc02-4fc11c39983b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 9 192.1.1.1\n",
            "12 13 192.160.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"ENT_TYPE\": \"PERSON\"}]\n",
        "matcher.add(\"personEnt\",  [pattern])\n",
        "doc = nlp(\"Bill Gates visited Berlin.\")\n",
        "matches = matcher(doc)\n",
        "for mid, start, end in matches:\n",
        "  print(start, end, doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxRbdzm6dsac",
        "outputId": "de701c60-52bc-401f-9d77-5aadd83423b3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 Bill\n",
            "1 2 Gates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I have an acccount with chime since 2017\")\n",
        "print(doc.ents)\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": [{\"LOWER\": \"chime\"}]}]\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.add_patterns(patterns)\n",
        "print(doc.ents)\n",
        "print(doc[5].ent_type_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08MlxEpgeEd8",
        "outputId": "6f123c78-9bd5-4140-f018-43603202ba14"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2017,)\n",
            "(2017,)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sVwmBhNOeXUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}